# Objective
The objective from this milestone is to define an equation and find the local mininmum for the equation. <br>
This was done by applying gradiant decent in three form :<br>
1. Normal gradiant decent  $X_{n+1} = X_n - \eta \nabla F(x)$
2. Netwon raphson decent $X_{n+1} = X_n - H^{-1} \nabla F(x)$ where H is the hessian matrix 
3. Steppest gradint decent:<br>
  this algorithim depend on changing the value of learning rate at every iteration 
 
  
